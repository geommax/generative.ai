{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdab23bf",
   "metadata": {},
   "source": [
    "## Decoder-only models provide Autoregressive completion\n",
    "- Text generation & creative writing\n",
    "- Conversation & chatbots\n",
    "- Instruction-following tasks (classification, QA, summarization)\n",
    "- Code generation & reasoning\n",
    "- Translation & multi-lingual tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58028775",
   "metadata": {},
   "source": [
    "##### GPT-2 = Decoder-only Transformer\n",
    "\n",
    "- No encoder\n",
    "- No cross-attention\n",
    "- Only masked self-attention\n",
    "- Trained with next-token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b2bf65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cef67cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2\"  # GPT-2 small: 12 layers, 12 heads\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    model_name,\n",
    "    output_attentions=True,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed06717",
   "metadata": {},
   "source": [
    "GPT2 Model ရဲ့ ပထမဆုံး Embedding Layer က word token embedding ပါ၊ 50257 tokens ရှိပါတယ်။\n",
    "ဒုတိယ wte embedding layer မှာဆိုရင် 1024x768 dimension ရှိတဲ့ context window = 1024 tokens ကောင်ကတော့ word positional embedding ပါ။ \n",
    "\n",
    "Decoder Only GPT မှာ \n",
    "No sinusoidal encoding, no rotary embeddings ပါ။ \n",
    "\n",
    "absolute positions ကိုသာအသုံးပြုပြီး learn လုပ်ပါတယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8af8ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding params: 38,597,376\n",
      "Position embedding params: 786,432\n"
     ]
    }
   ],
   "source": [
    "wte_params = model.transformer.wte.weight.numel()\n",
    "wpe_params = model.transformer.wpe.weight.numel()\n",
    "\n",
    "print(\"Token embedding params:\", f\"{wte_params:,}\")\n",
    "print(\"Position embedding params:\", f\"{wpe_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2a895ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_attn params: 1771776\n",
      "c_proj params: 590592\n"
     ]
    }
   ],
   "source": [
    "block = model.transformer.h[0]\n",
    "\n",
    "print(\"c_attn params:\", block.attn.c_attn.weight.numel() + block.attn.c_attn.bias.numel())\n",
    "print(\"c_proj params:\", block.attn.c_proj.weight.numel() + block.attn.c_proj.bias.numel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbac006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "text = \"Recurrent Neural Network will change the\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b75232a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a680885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 7, 50257])\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "print(\"Logits shape:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1472aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hidden state tensors: 13\n",
      "Embedding output shape: torch.Size([1, 7, 768])\n",
      "Last layer output shape: torch.Size([1, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = outputs.hidden_states\n",
    "\n",
    "print(\"Total hidden state tensors:\", len(hidden_states))\n",
    "print(\"Embedding output shape:\", hidden_states[0].shape)\n",
    "print(\"Last layer output shape:\", hidden_states[-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22a046b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total attention layers: 12\n",
      "One layer attention shape: torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "attentions = outputs.attentions\n",
    "\n",
    "print(\"Total attention layers:\", len(attentions))\n",
    "print(\"One layer attention shape:\", attentions[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16db6e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6984, 0.3016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4638, 0.2843, 0.2520, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3511, 0.2360, 0.2186, 0.1943, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3529, 0.1802, 0.1466, 0.1212, 0.1992, 0.0000, 0.0000],\n",
      "        [0.3420, 0.1347, 0.1247, 0.1247, 0.1232, 0.1506, 0.0000],\n",
      "        [0.2430, 0.1132, 0.1216, 0.1333, 0.1036, 0.1298, 0.1555]])\n"
     ]
    }
   ],
   "source": [
    "layer = 0\n",
    "head = 11\n",
    "\n",
    "attn = attentions[layer][0, head]\n",
    "print(attn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece6e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.transformer.h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f01ddcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.n_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2166407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.n_embd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dca9fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPT-2 parameters: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "def count_params(module):\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "print(\"Total GPT-2 parameters:\", f\"{count_params(model):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "930cc6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention params per layer: 2,362,368\n",
      "MLP params per layer: 4,722,432\n"
     ]
    }
   ],
   "source": [
    "block = model.transformer.h[0]\n",
    "\n",
    "attn_params = count_params(block.attn)\n",
    "mlp_params = count_params(block.mlp)\n",
    "\n",
    "print(\"Attention params per layer:\", f\"{attn_params:,}\")\n",
    "print(\"MLP params per layer:\", f\"{mlp_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40f47a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 2304])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.attn.c_attn.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3e75898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token:  way\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = logits[:, -1, :]\n",
    "next_token_id = torch.argmax(next_token_logits, dim=-1)\n",
    "\n",
    "print(\"Next token:\", tokenizer.decode(next_token_id))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
